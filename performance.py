import time
import asyncio
import logging
from typing import Dict, Any, Callable, Optional, List
from functools import wraps
from dataclasses import dataclass
from datetime import datetime, timedelta
from redis_cache import redis_cache_adapter
from config import Config

logger = logging.getLogger("GroupCheckInBot")


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""

    count: int = 0
    total_time: float = 0
    avg_time: float = 0
    max_time: float = 0
    min_time: float = float("inf")
    last_updated: float = 0


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.metrics: Dict[str, PerformanceMetrics] = {}
        self.slow_operations_count = 0
        self.start_time = time.time()

    def track(self, operation_name: str):
        """æ€§èƒ½è·Ÿè¸ªè£…é¥°å™¨"""

        def decorator(func):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    execution_time = time.time() - start_time
                    self._record_metrics(operation_name, execution_time)

            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = func(*args, **kwargs)
                    return result
                finally:
                    execution_time = time.time() - start_time
                    self._record_metrics(operation_name, execution_time)

            return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

        return decorator

    def _record_metrics(self, operation_name: str, execution_time: float):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        if operation_name not in self.metrics:
            self.metrics[operation_name] = PerformanceMetrics()

        metrics = self.metrics[operation_name]
        metrics.count += 1
        metrics.total_time += execution_time
        metrics.avg_time = metrics.total_time / metrics.count
        metrics.max_time = max(metrics.max_time, execution_time)
        metrics.min_time = min(metrics.min_time, execution_time)
        metrics.last_updated = time.time()

        # è®°å½•æ…¢æ“ä½œ
        if execution_time > 1.0:  # è¶…è¿‡1ç§’è§†ä¸ºæ…¢æ“ä½œ
            self.slow_operations_count += 1
            logger.warning(
                f"â±ï¸ æ…¢æ“ä½œæ£€æµ‹: {operation_name} è€—æ—¶ {execution_time:.3f}ç§’"
            )

    def get_metrics(self, operation_name: str) -> Optional[PerformanceMetrics]:
        """è·å–æŒ‡å®šæ“ä½œçš„æ€§èƒ½æŒ‡æ ‡"""
        return self.metrics.get(operation_name)

    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        uptime = time.time() - self.start_time

        # è®¡ç®—å†…å­˜ä½¿ç”¨ï¼ˆè¿‘ä¼¼å€¼ï¼‰
        try:
            import psutil

            process = psutil.Process()
            memory_usage_mb = process.memory_info().rss / 1024 / 1024
        except ImportError:
            memory_usage_mb = 0

        # æ±‡æ€»æŒ‡æ ‡
        metrics_summary = {}
        for op_name, metrics in self.metrics.items():
            if metrics.count > 0:
                metrics_summary[op_name] = {
                    "count": metrics.count,
                    "avg": metrics.avg_time,
                    "max": metrics.max_time,
                    "min": metrics.min_time if metrics.min_time != float("inf") else 0,
                }

        return {
            "uptime": uptime,
            "memory_usage_mb": memory_usage_mb,
            "slow_operations_count": self.slow_operations_count,
            "total_operations": sum(m.count for m in self.metrics.values()),
            "metrics_summary": metrics_summary,
        }

    def reset_metrics(self):
        """é‡ç½®æ€§èƒ½æŒ‡æ ‡"""
        self.metrics.clear()
        self.slow_operations_count = 0


class RetryManager:
    """é‡è¯•ç®¡ç†å™¨"""

    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay

    def with_retry(self, operation_name: str = "unknown"):
        """é‡è¯•è£…é¥°å™¨"""

        def decorator(func):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                last_exception = None
                for attempt in range(self.max_retries + 1):
                    try:
                        return await func(*args, **kwargs)
                    except Exception as e:
                        last_exception = e
                        if attempt == self.max_retries:
                            break

                        delay = self.base_delay * (2**attempt)  # æŒ‡æ•°é€€é¿
                        logger.warning(
                            f"ğŸ”„ é‡è¯• {operation_name} (å°è¯• {attempt + 1}/{self.max_retries}): {e}"
                        )
                        await asyncio.sleep(delay)

                logger.error(
                    f"âŒ {operation_name} é‡è¯•{self.max_retries}æ¬¡åå¤±è´¥: {last_exception}"
                )
                raise last_exception

            return async_wrapper

        return decorator


class GlobalCache:
    """å…¨å±€ç¼“å­˜ç®¡ç†å™¨ - æ”¯æŒRedis"""

    def __init__(self, default_ttl: int = 300):
        self._memory_cache: Dict[str, Any] = {}
        self._memory_ttl: Dict[str, float] = {}
        self._hits = 0
        self._misses = 0
        self.default_ttl = default_ttl

        # æ˜¯å¦ä½¿ç”¨Redis
        self.use_redis = Config.REDIS_ENABLED

        # ç»Ÿè®¡
        self._redis_hits = 0
        self._redis_misses = 0
        self._redis_errors = 0
        self._redis_sets = 0

    def get(self, key: str) -> Any:
        """ã€å·²åºŸå¼ƒã€‘è¯·ä½¿ç”¨å¼‚æ­¥æ–¹æ³• aget()"""
        logger.warning(
            f"âš ï¸ ä½¿ç”¨äº†åºŸå¼ƒçš„åŒæ­¥ç¼“å­˜æ–¹æ³•: get('{key}')ï¼Œè¯·æ”¹ç”¨ await global_cache.aget()"
        )
        # é™çº§è¡Œä¸ºï¼šåªæ£€æŸ¥å†…å­˜ç¼“å­˜
        if key in self._memory_ttl and time.time() < self._memory_ttl[key]:
            return self._memory_cache.get(key)
        return None

    def set(self, key: str, value: Any, ttl: int = None):
        """ã€å·²åºŸå¼ƒã€‘è¯·ä½¿ç”¨å¼‚æ­¥æ–¹æ³• aset()"""
        logger.warning(
            f"âš ï¸ ä½¿ç”¨äº†åºŸå¼ƒçš„åŒæ­¥ç¼“å­˜æ–¹æ³•: set('{key}')ï¼Œè¯·æ”¹ç”¨ await global_cache.aset()"
        )
        # é™çº§è¡Œä¸ºï¼šåªè®¾ç½®å†…å­˜ç¼“å­˜
        if ttl is None:
            ttl = self.default_ttl
        self._memory_cache[key] = value
        self._memory_ttl[key] = time.time() + ttl

    def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜å€¼"""
        self._memory_cache.pop(key, None)
        self._memory_ttl.pop(key, None)

    # ========== å¼‚æ­¥æ–¹æ³•ï¼ˆæ–°ä»£ç ä½¿ç”¨ï¼‰ ==========
    async def aget(self, key: str, default: Any = None) -> Any:
        """å¼‚æ­¥è·å–ç¼“å­˜å€¼ï¼ˆä¼˜å…ˆRedisï¼Œåå¤‡å†…å­˜ï¼‰"""
        # å¦‚æœå¯ç”¨Redisï¼Œå…ˆå°è¯•Redis
        if self.use_redis:
            try:
                value = await redis_cache_adapter.get(key)
                if value is not None:
                    self._redis_hits += 1
                    return value
                self._redis_misses += 1
            except Exception as e:
                logger.warning(f"Redis agetå¤±è´¥ ({key}): {e}")
                self._redis_errors += 1

        # åå¤‡ï¼šå†…å­˜ç¼“å­˜
        if key in self._memory_ttl and time.time() < self._memory_ttl[key]:
            self._hits += 1
            return self._memory_cache.get(key, default)

        self._misses += 1
        return default

    async def aset(self, key: str, value: Any, ttl: int = None):
        """å¼‚æ­¥è®¾ç½®ç¼“å­˜å€¼"""
        # è®¾ç½®å†…å­˜ç¼“å­˜ (ç›´æ¥å†™ï¼Œä¸è°ƒç”¨ self.set)
        if ttl is None:
            ttl = self.default_ttl
        self._memory_cache[key] = value
        self._memory_ttl[key] = time.time() + ttl

        # å¦‚æœå¯ç”¨Redisï¼Œä¹Ÿè®¾ç½®åˆ°Redis
        if self.use_redis:
            try:
                await redis_cache_adapter.set(key, value, ttl)
            except Exception as e:
                logger.warning(f"Redis asetå¤±è´¥: {e}")
                self._redis_errors += 1

    async def adelete(self, *keys: str) -> int:
        """å¼‚æ­¥åˆ é™¤ç¼“å­˜å€¼"""
        deleted = 0

        # åˆ é™¤å†…å­˜ç¼“å­˜
        for key in keys:
            if self._memory_cache.pop(key, None) is not None:
                self._memory_ttl.pop(key, None)
                deleted += 1
            else:
                self._memory_ttl.pop(key, None)

        # åˆ é™¤Redisç¼“å­˜
        if self.use_redis:
            try:
                redis_deleted = await redis_cache_adapter.delete(*keys)
                # Redisåˆ é™¤è®¡æ•°ä¸å½±å“è¿”å›å€¼ï¼Œå› ä¸ºå†…å­˜å·²åˆ 
            except Exception as e:
                logger.warning(f"Redis adeleteå¤±è´¥: {e}")
                self._redis_errors += 1

        return deleted

    async def setnx(self, key: str, value: Any, ttl: int = None) -> bool:
        """
        åŸå­æ“ä½œï¼šå¦‚æœkeyä¸å­˜åœ¨åˆ™è®¾ç½®
        è¿”å›ï¼šTrue-æˆåŠŸè®¾ç½®ï¼ˆä¹‹å‰ä¸å­˜åœ¨ï¼‰ï¼ŒFalse-keyå·²å­˜åœ¨
        """
        if ttl is None:
            ttl = self.default_ttl

        # ä¼˜å…ˆä½¿ç”¨Redisçš„åŸå­æ“ä½œ
        if self.use_redis:
            try:
                from redis_manager import redis_manager

                # ä½¿ç”¨Redisçš„SETNXå‘½ä»¤
                success = await redis_manager.setnx(key, value, ttl)
                if success:
                    # åŒæ­¥è®¾ç½®å†…å­˜ç¼“å­˜
                    self._memory_cache[key] = value
                    self._memory_ttl[key] = time.time() + ttl
                return success
            except Exception as e:
                logger.warning(f"Redis setnxå¤±è´¥ ({key}): {e}")
                self._redis_errors += 1

        # é™çº§ï¼šä½¿ç”¨å†…å­˜ç¼“å­˜çš„ç®€å•æ£€æŸ¥
        if key in self._memory_ttl and time.time() < self._memory_ttl[key]:
            return False
        self._memory_cache[key] = value
        self._memory_ttl[key] = time.time() + ttl
        return True

    def clear_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜ - åŒæ­¥"""
        current_time = time.time()
        expired_keys = [
            key for key, expiry in self._memory_ttl.items() if current_time >= expiry
        ]
        for key in expired_keys:
            self._memory_cache.pop(key, None)
            self._memory_ttl.pop(key, None)

        if expired_keys:
            logger.debug(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜")

    async def aclear_expired(self):
        """å¼‚æ­¥æ¸…ç†è¿‡æœŸç¼“å­˜"""
        # æ¸…ç†å†…å­˜ç¼“å­˜
        self.clear_expired()

        # Redisè‡ªåŠ¨è¿‡æœŸï¼Œä¸éœ€è¦æ‰‹åŠ¨æ¸…ç†

    def clear_all(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜ - åŒæ­¥"""
        self._memory_cache.clear()
        self._memory_ttl.clear()
        logger.info("æ‰€æœ‰å†…å­˜ç¼“å­˜å·²æ¸…ç†")

    async def aclear_all(self):
        """å¼‚æ­¥æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        # æ¸…ç†å†…å­˜ç¼“å­˜
        self.clear_all()

        # æ¸…ç†Redisç¼“å­˜
        if self.use_redis:
            try:
                await redis_cache_adapter.clear_all()
            except Exception as e:
                logger.warning(f"Redis aclear_allå¤±è´¥: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self._hits + self._misses
        hit_rate = self._hits / total if total > 0 else 0

        stats = {
            "memory_size": len(self._memory_cache),
            "memory_hits": self._hits,
            "memory_misses": self._misses,
            "memory_hit_rate": hit_rate,
            "total_operations": total,
        }

        if self.use_redis:
            redis_total = self._redis_hits + self._redis_misses
            redis_hit_rate = self._redis_hits / redis_total if redis_total > 0 else 0

            stats.update(
                {
                    "redis_hits": self._redis_hits,
                    "redis_misses": self._redis_misses,
                    "redis_errors": self._redis_errors,
                    "redis_hit_rate": redis_hit_rate,
                    "redis_enabled": self.use_redis,
                }
            )

        return stats


class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨"""

    def __init__(self):
        self._tasks: Dict[str, asyncio.Task] = {}
        self._task_count = 0

    async def create_task(self, coro, name: str = None) -> asyncio.Task:
        """åˆ›å»ºå¹¶è·Ÿè¸ªä»»åŠ¡"""
        if not name:
            self._task_count += 1
            name = f"task_{self._task_count}"

        task = asyncio.create_task(coro, name=name)
        self._tasks[name] = task

        # ä»»åŠ¡å®Œæˆåè‡ªåŠ¨æ¸…ç†
        task.add_done_callback(lambda t: self._tasks.pop(name, None))

        return task

    async def cancel_task(self, name: str):
        """å–æ¶ˆæŒ‡å®šä»»åŠ¡"""
        task = self._tasks.get(name)
        if task and not task.done():
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
            self._tasks.pop(name, None)

    async def cancel_all_tasks(self):
        """å–æ¶ˆæ‰€æœ‰ä»»åŠ¡"""
        tasks_to_cancel = list(self._tasks.values())
        for task in tasks_to_cancel:
            if not task.done():
                task.cancel()

        if tasks_to_cancel:
            await asyncio.gather(*tasks_to_cancel, return_exceptions=True)
            self._tasks.clear()

    def get_task_count(self) -> int:
        """è·å–ä»»åŠ¡æ•°é‡"""
        return len(self._tasks)

    def get_active_tasks(self) -> List[str]:
        """è·å–æ´»è·ƒä»»åŠ¡åˆ—è¡¨"""
        return [name for name, task in self._tasks.items() if not task.done()]

    async def cleanup_tasks(self):
        """æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡"""
        completed_tasks = [name for name, task in self._tasks.items() if task.done()]
        for name in completed_tasks:
            self._tasks.pop(name, None)

        if completed_tasks:
            logger.debug(f"æ¸…ç†äº† {len(completed_tasks)} ä¸ªå·²å®Œæˆä»»åŠ¡")


class MessageDeduplicate:
    """æ¶ˆæ¯å»é‡ç®¡ç†å™¨"""

    def __init__(self, ttl: int = 60):
        self._messages: Dict[str, float] = {}
        self.ttl = ttl

    def is_duplicate(self, message_id: str) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦é‡å¤"""
        current_time = time.time()

        # æ¸…ç†è¿‡æœŸæ¶ˆæ¯
        expired_messages = [
            msg_id
            for msg_id, timestamp in self._messages.items()
            if current_time - timestamp > self.ttl
        ]
        for msg_id in expired_messages:
            self._messages.pop(msg_id, None)

        # æ£€æŸ¥é‡å¤
        if message_id in self._messages:
            return True

        # è®°å½•æ–°æ¶ˆæ¯
        self._messages[message_id] = current_time
        return False

    def clear_expired(self):
        """æ¸…ç†è¿‡æœŸæ¶ˆæ¯"""
        current_time = time.time()
        expired_messages = [
            msg_id
            for msg_id, timestamp in self._messages.items()
            if current_time - timestamp > self.ttl
        ]
        for msg_id in expired_messages:
            self._messages.pop(msg_id, None)


# é”™è¯¯å¤„ç†è£…é¥°å™¨
def handle_database_errors(func):
    """æ•°æ®åº“é”™è¯¯å¤„ç†è£…é¥°å™¨"""

    @wraps(func)
    async def async_wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥ {func.__name__}: {e}")
            # å¯ä»¥æ ¹æ®å¼‚å¸¸ç±»å‹è¿›è¡Œä¸åŒçš„å¤„ç†
            raise

    return async_wrapper


def handle_telegram_errors(func):
    """Telegram APIé”™è¯¯å¤„ç†è£…é¥°å™¨"""

    @wraps(func)
    async def async_wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Telegram APIæ“ä½œå¤±è´¥ {func.__name__}: {e}")
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é‡è¯•é€»è¾‘æˆ–é™çº§å¤„ç†
            raise

    return async_wrapper


# å…¨å±€å®ä¾‹
performance_monitor = PerformanceMonitor()
retry_manager = RetryManager(max_retries=3, base_delay=1.0)
global_cache = GlobalCache(default_ttl=300)
task_manager = TaskManager()
global_msg_deduplicate = MessageDeduplicate(ttl=60)


# ä¾¿æ·è£…é¥°å™¨
def track_performance(operation_name: str):
    """æ€§èƒ½è·Ÿè¸ªè£…é¥°å™¨"""
    return performance_monitor.track(operation_name)


def with_retry(operation_name: str = "unknown", max_retries: int = 3):
    """é‡è¯•è£…é¥°å™¨"""
    retry_mgr = RetryManager(max_retries=max_retries)
    return retry_mgr.with_retry(operation_name)


def message_deduplicate_decorator(ttl: int = 60):
    """æ¶ˆæ¯å»é‡è£…é¥°å™¨"""
    deduplicate = MessageDeduplicate(ttl=ttl)

    def decorator(func):
        @wraps(func)
        async def wrapper(message, *args, **kwargs):
            message_id = f"{message.chat.id}_{message.message_id}"
            if deduplicate.is_duplicate(message_id):
                logger.debug(f"è·³è¿‡é‡å¤æ¶ˆæ¯: {message_id}")
                return
            return await func(message, *args, **kwargs)

        return wrapper

    return decorator


# ç®€å†™
message_deduplicate = message_deduplicate_decorator()
